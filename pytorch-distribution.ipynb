{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e3b31d2-c116-475d-9da5-35f26e42179f",
   "metadata": {},
   "source": [
    "# PyTorch 分布式实践\n",
    "\n",
    "本文主要对 `PyTorch` 的[分布式 API ](https://pytorch.org/docs/stable/distributed.html#distributed-basics)做了一些非常简单的探索。\n",
    "\n",
    "另外还有两个支持分布式的 `Accuracy` 和 `Mean Average Precision` 的实现，分别使用 `reduce` 和 `gather`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c43525f-0d30-49c8-9767-c6a04c71caec",
   "metadata": {},
   "source": [
    "## 环境\n",
    "\n",
    "文章的所有代码均可实际运行，下面是文章写作时依赖的软件版本，你也完全可以尝试其他版本。\n",
    "\n",
    "* Python==3.7.0\n",
    "* torch==1.10.0\n",
    "\n",
    "你也可以直接从 Colab 中实验本文的代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79ac6e-9cc0-4f8e-931f-83cd73880313",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "430346da-1482-4de2-b49e-5735b91f7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def clear_log():\n",
    "    with open(\"/tmp/pytorch-dist.log\", \"w\") as f:\n",
    "        f.write(\"\")\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f59e5cb2-b4db-40e6-810c-e62865b6003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/helper.py\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/helper.py\n",
    "\n",
    "import torch.distributed as dist\n",
    "import logging\n",
    "\n",
    "\n",
    "def init_logger():\n",
    "    assert dist.is_initialized()\n",
    "    rank = dist.get_rank()\n",
    "    role = \"master\" if rank == 0 else \"slave\"\n",
    "\n",
    "    logging.basicConfig(filename=\"/tmp/pytorch-dist.log\",\n",
    "                        filemode='a',\n",
    "                        format=f'{role.ljust(6)} ==> %(asctime)8s %(levelname)5s %(message)4s',\n",
    "                        datefmt='%H:%M:%S',\n",
    "                        level=logging.DEBUG)\n",
    "\n",
    "    \n",
    "def is_master():\n",
    "    return dist.get_rank() == 0\n",
    "\n",
    "\n",
    "def is_slave():\n",
    "    return dist.get_rank() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a269b-4068-45df-ac03-d73d48ad2c02",
   "metadata": {},
   "source": [
    "## 获取环境信息\n",
    "\n",
    "用于获取当前节点的环境信息，比如使用的 backend，当前节点的 rank，以及所有节点的数量等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4147746-afbd-4171-8e36-a49ed317933b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test.py\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test.py\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "from helper import init_logger, is_master, is_slave\n",
    "\n",
    "torch.distributed.init_process_group(backend=\"gloo\")\n",
    "\n",
    "init_logger()\n",
    "\n",
    "logging.info(f\"backend: {torch.distributed.get_backend()}\")\n",
    "logging.info(f\"rank: {torch.distributed.get_rank()}\")\n",
    "logging.info(f\"world size: {torch.distributed.get_world_size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e46f9cb-ba69-40c0-a9cc-74739194cbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master ==> 13:52:24  INFO backend: gloo\n",
      "master ==> 13:52:24  INFO rank: 0\n",
      "master ==> 13:52:24  INFO world size: 2\n",
      "slave  ==> 13:52:24  INFO backend: gloo\n",
      "slave  ==> 13:52:24  INFO rank: 1\n",
      "slave  ==> 13:52:24  INFO world size: 2\n"
     ]
    }
   ],
   "source": [
    "!echo > /tmp/pytorch-dist.log && torchrun --nproc_per_node 2 --nnodes 1 /tmp/test.py && cat /tmp/pytorch-dist.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a69d3-6e3b-4859-af9a-5a28ac801295",
   "metadata": {},
   "source": [
    "## 分布式 Key-Value 存储\n",
    "\n",
    "类似分布式的字典数据结构，但 Key Value 存储只允许存字符串，所以似乎一般是用来在节点之间同步一些元信息的。\n",
    "\n",
    "当然非要存 `torch.Tensor` 也是可以的，只需要 base64 一下就可以了，下面的例子有展示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f2652a7-104b-40f0-bc75-1c92a40ba6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test.py\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test.py\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "from base64 import b64encode, b64decode\n",
    "import torch.distributed as dist\n",
    "import logging\n",
    "from helper import init_logger, is_master, is_slave\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "init_logger()\n",
    "\n",
    "store = dist.TCPStore(\n",
    "    host_name=\"127.0.0.1\",\n",
    "    port=5848,\n",
    "    world_size=dist.get_world_size(),\n",
    "    is_master=is_master(),\n",
    ")\n",
    "\n",
    "if is_slave():\n",
    "    store.set(\"the_key\", \"Hi master\")\n",
    "    logging.info(\"slave has set the key\")\n",
    "\n",
    "if is_master():\n",
    "    result = store.get(\"the_key\")\n",
    "    logging.info(f\"master has get the value: {result}\")\n",
    "    \n",
    "    b64tensor = b64encode(pickle.dumps(torch.rand(4))).decode()\n",
    "    store.set(\"another_key\", b64tensor)\n",
    "    logging.info(f\"master set a torch.Tensor object to the same key\")\n",
    "    time.sleep(2)  # should wait for the slave to read the data before quit\n",
    "\n",
    "if is_slave():\n",
    "    time.sleep(1)  # wait for master to set the torch.Tensor object\n",
    "    store.get(\"another_key\")\n",
    "    tensor = pickle.loads(b64decode(store.get(\"another_key\")))\n",
    "    logging.info(f\"slave got object from the same key {tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e48e25-deb4-43ef-af7e-fd51a3b8ed5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slave  ==> 13:52:51  INFO slave has set the key\n",
      "master ==> 13:52:51  INFO master has get the value: b'Hi master'\n",
      "master ==> 13:52:51  INFO master set a torch.Tensor object to the same key\n",
      "slave  ==> 13:52:52  INFO slave got object from the same key tensor([0.4105, 0.1806, 0.0714, 0.2835])\n"
     ]
    }
   ],
   "source": [
    "!echo > /tmp/pytorch-dist.log && torchrun --nproc_per_node 2 --nnodes 1 /tmp/test.py && cat /tmp/pytorch-dist.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f0bfd6-143a-4b71-a048-bce630748a5b",
   "metadata": {},
   "source": [
    "## 点到点数据传输\n",
    "\n",
    "某个节点定向向另外一个节点发送数据。\n",
    "\n",
    "点到点只能传 `torch.Tensor`，接收方需要提前创建好承载的 `torch.Tensor` 变量传入 `recv` 中，然后 `recv` 会做 inplace 修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102aeff5-f401-4fef-8bd6-6f4aa2bb64ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test.py\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test.py\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "from base64 import b64encode, b64decode\n",
    "import torch.distributed as dist\n",
    "import logging\n",
    "from helper import init_logger, is_master, is_slave\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "init_logger()\n",
    "\n",
    "if is_master():\n",
    "    res = torch.rand(4)\n",
    "    dist.recv(res)\n",
    "    logging.info(f\"master has recv a tensor: {res}\")\n",
    "    time.sleep(2)\n",
    "\n",
    "if is_slave():\n",
    "    payload = torch.rand(4)\n",
    "    time.sleep(1)  # wait until the master is ready\n",
    "    res = dist.send(payload, 0)\n",
    "    logging.info(f\"slave has sent a tensor: {payload}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c64d5241-7bf0-4731-983a-923c7bfd643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slave  ==> 13:53:03  INFO slave has sent a tensor: tensor([0.1837, 0.5282, 0.9892, 0.8568])\n",
      "master ==> 13:53:03  INFO master has recv a tensor: tensor([0.1837, 0.5282, 0.9892, 0.8568])\n"
     ]
    }
   ],
   "source": [
    "!echo > /tmp/pytorch-dist.log && torchrun --nproc_per_node 2 --nnodes 1 /tmp/test.py && cat /tmp/pytorch-dist.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d6c86-daeb-470c-9451-71b1b5667e0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Collective functions\n",
    "\n",
    "这是本文的主角，在实现一些分布式的功能时，用的最多的应该是这类方法了。\n",
    "\n",
    "这类方法一般来说会同时操作所有的节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d48c33-69b6-4286-a036-df7d3324038e",
   "metadata": {},
   "source": [
    "### broadcast\n",
    "\n",
    "将某个 `torch.Tensor` 同步给全部其他节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a94d94-265f-4bf7-8d40-de4c62664964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test.py\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test.py\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import logging\n",
    "from helper import init_logger, is_master, is_slave\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "init_logger()\n",
    "\n",
    "if is_slave():\n",
    "    tensor = torch.zeros(3)\n",
    "\n",
    "if is_master():\n",
    "    tensor = torch.rand(3)\n",
    "\n",
    "dist.broadcast(tensor, src=0)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "logging.info(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ebe39b-fb45-4f84-94a7-2304d284381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master ==> 13:53:15  INFO tensor([0.3944, 0.0291, 0.6223])\n",
      "slave  ==> 13:53:15  INFO tensor([0.3944, 0.0291, 0.6223])\n"
     ]
    }
   ],
   "source": [
    "!echo > /tmp/pytorch-dist.log && torchrun --nproc_per_node 2 --nnodes 1 /tmp/test.py && cat /tmp/pytorch-dist.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e54685a-6354-4606-b546-5f55bf9b22d4",
   "metadata": {},
   "source": [
    "### broadcast_object_list\n",
    "\n",
    "将某个包含 Python object 的数组，同步给所有其他节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "157ad8a9-308f-425d-af18-d1a635d54ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test.py\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test.py\n",
    "\n",
    "import time\n",
    "import torch.distributed as dist\n",
    "import logging\n",
    "from helper import init_logger, is_master, is_slave\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "init_logger()\n",
    "\n",
    "if is_slave():\n",
    "    objects = [None, None, None]\n",
    "\n",
    "if is_master():\n",
    "    objects = [\"foo\", 12, {1: 2}]\n",
    "\n",
    "dist.broadcast_object_list(objects, src=0)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "logging.info(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d627df54-e4cb-4d0d-8548-42e61e56d894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master ==> 13:53:22  INFO ['foo', 12, {1: 2}]\n",
      "slave  ==> 13:53:22  INFO ['foo', 12, {1: 2}]\n"
     ]
    }
   ],
   "source": [
    "!echo > /tmp/pytorch-dist.log && torchrun --nproc_per_node 2 --nnodes 1 /tmp/test.py && cat /tmp/pytorch-dist.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c48b4-1695-4a9b-a7c2-b57ab57312c0",
   "metadata": {},
   "source": [
    "### all_reduce\n",
    "\n",
    "reduce 意为「聚合」。\n",
    "\n",
    "该操作将对所有节点上的某个 `torch.Tensor` 进行某个聚合操作 `torch.distributed.ReduceOp`（可以是求均值、求和、求最小/最大值等），然后再将结果同步到所有的节点上。\n",
    "\n",
    "典型的使用场景是梯度同步：\n",
    "\n",
    "所有节点首先分别用自己的 batch 获得梯度，然后节点之间将各自获得梯度求均值，再将结果同步给所有的节点。\n",
    "\n",
    "PyTorch 本身的 `torch.nn.parallel.DistributedDataParallel` 内部也是使用了该方法来同步梯度，因此在实际的训练中直接使用 `DistributedDataParallel` 就好，如果要用 `all_reduce` 自己实现分布式训练还有其他非常多的细节，感兴趣的同学可以查看 `DistributedDataParallel` 的源码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8525c2b8-ab9b-4066-81bc-4e6926dc650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test.py\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/test.py\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import logging\n",
    "from helper import init_logger, is_master, is_slave\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "init_logger()\n",
    "\n",
    "if is_master():\n",
    "    tensor = torch.tensor([3, 4])\n",
    "\n",
    "if is_slave():\n",
    "    tensor = torch.tensor([5, 6])\n",
    "\n",
    "logging.info(f\"before reduce: {tensor}\")\n",
    "\n",
    "dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n",
    "\n",
    "logging.info(f\"after reduce: {tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a3cc1-5541-4737-8968-e0d0604c908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo > /tmp/pytorch-dist.log && torchrun --nproc_per_node 2 --nnodes 1 /tmp/test.py && cat /tmp/pytorch-dist.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6028781-0745-4ae4-8edd-469fd481678f",
   "metadata": {},
   "source": [
    "### reduce\n",
    "\n",
    "对所有节点上的 `torch.Tensor` 做某个聚合操作，最后仅同步到单个节点。\n",
    "\n",
    "典型的应用场景是某一些支持分布式的 `Metric` 的实现。\n",
    "\n",
    "例如目前可用的节点有 2 个，要计算得分的样本有 100 个，我们可以把这 100 个样本分成两份，然后交给两个节点同步计算每个样本的得分，然后最后使用 `reduce` 操作对所有 100 个样本计算均值，再同步到 `master`（rank=0）的节点。再由 `master` 节点来打日志会绘制曲线。\n",
    "\n",
    "下面会有一个分布式计算 `Accuracy` 的例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b1e13-2548-4a97-9786-4b516db59013",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/test.py\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import logging\n",
    "from helper import init_logger, is_master, is_slave\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "init_logger()\n",
    "\n",
    "if is_master():\n",
    "    tensor = torch.tensor([3, 4])\n",
    "\n",
    "if is_slave():\n",
    "    tensor = torch.tensor([5, 6])\n",
    "\n",
    "logging.info(f\"before reduce: {tensor}\")\n",
    "\n",
    "dist.reduce(tensor, op=dist.ReduceOp.SUM, dst=0)\n",
    "\n",
    "logging.info(f\"after reduce: {tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48b6e9-a47e-4949-913a-0446ea3864c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo > /tmp/pytorch-dist.log && torchrun --nproc_per_node 2 --nnodes 1 /tmp/test.py && cat /tmp/pytorch-dist.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed3363b-2220-4787-9352-9d58110b89d3",
   "metadata": {},
   "source": [
    "### all_gather\n",
    "\n",
    "gather 意为「聚集」。\n",
    "\n",
    "跟名称一样，将所有节点上的 `torch.Tensor` 搜集到一个 `list` 中，然后将该 list 同步给所有的节点。\n",
    "\n",
    "`all_gather` 与之对应也有一个 `gather` 操作，其不同点仅仅在于最终结果是同步给单个节点还是全部节点（与 `reduce` 和 `all_reduce` 的区别相同）。\n",
    "\n",
    "跟 `reduce` 操作的区别是，`gather` 操作仅仅是搜集张量，并不做任何的聚合操作。\n",
    "\n",
    "`gather` 方法用于处理比 `reduce` 方法要求更苛刻的场景，例如在全部节点上的所有的张量无法仅仅通过 `torch.distributed.ReduceOp` 来得到结果，而是需要更加复杂的计算。下面会使用 `gather` 操作来实现一个跟 `pycocotools` 相兼容的分布式版本的 `mAP Metric`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927fcf0-b354-41d1-8b42-a71a31087980",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/test.py\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import logging\n",
    "from helper import init_logger, is_master, is_slave\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "init_logger()\n",
    "\n",
    "if is_master():\n",
    "    tensor = torch.tensor([3, 4])\n",
    "\n",
    "if is_slave():\n",
    "    tensor = torch.tensor([5, 6])\n",
    "\n",
    "tensor_list = [torch.zeros(2, dtype=torch.int64) for _ in range(2)]\n",
    "\n",
    "dist.all_gather(tensor_list, tensor)\n",
    "\n",
    "logging.info(f\"gathered: {tensor_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affeced3-bde2-4c13-9245-fec41b5a0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo > /tmp/pytorch-dist.log && torchrun --nproc_per_node 2 --nnodes 1 /tmp/test.py && cat /tmp/pytorch-dist.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef917fab-5a5e-45a0-af88-612bc1dd2f79",
   "metadata": {},
   "source": [
    "### scatter\n",
    "\n",
    "scatter 意为「分发」。\n",
    "\n",
    "将某个节点上的一些张量（一个包含张量的 List），分别发个其余节点。接收张量的节点（也包含分发的节点自己）需要提前创建好用于接收张量的变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe9b149-5894-43f4-9468-8c164fab79e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/test.py\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import logging\n",
    "from helper import init_logger, is_master, is_slave\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "init_logger()\n",
    "tensor = torch.tensor([0, 0]).float()\n",
    "\n",
    "if is_master():\n",
    "    tensors = [torch.ones(2), torch.ones(2) * 2]\n",
    "else:\n",
    "    tensors = None\n",
    "dist.scatter(tensor, tensors, src=0)\n",
    "\n",
    "logging.info(f\"scattered: {tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d682751-ad4c-4540-932e-ffddf4396174",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo > /tmp/pytorch-dist.log && torchrun --nproc_per_node 2 --nnodes 1 /tmp/test.py && cat /tmp/pytorch-dist.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1531fb-13c8-4b3b-8388-2744f4808625",
   "metadata": {},
   "source": [
    "## 示例一：支持分布式的 Accuracy\n",
    "\n",
    "Accuracy 应该是最简单的 metric 了，只需要用预测正确的数量（tp + tn）除以总的样本数即可。\n",
    "\n",
    "在下面这个实现中，我们给 `Accuracy` 这个类定义了两个变量 `self._num_correct` 和 `self._num_samples`，分别用来记录当前正确预测的样本数量和当前已预测的总的样本数量。在分布式环境下，不同的节点会对仅属于该节点的数据计算这两个值。当全部数据预测完毕之后，调用 `compute` 方法获取最后的结果。在 `compute` 方法内部，会使用 `dist.reduce` 操作来将所有节点的 `self._num_correct` 和 `self._num_samples` 相加，然后把结果发送给 `rank==0` 的节点。\n",
    "\n",
    "该实现也支持单进程模式，实际上只需要一条 `if` 语句就实现了，细节可以参考代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f53bb-a36d-42a1-889b-4f93c9f0df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/metric.py\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "class Accuracy:\n",
    "    \"\"\"预测正确的样本数 / 总的样本数\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self._num_correct = torch.tensor(0)\n",
    "        self._num_samples = torch.tensor(0)\n",
    "\n",
    "    def update(self, labels, logits):\n",
    "        \"\"\"计算每个 mini batch 的结果\n",
    "\n",
    "        Args:\n",
    "            labels(torch.Tensor): 标签，一维的向量\n",
    "            logits(torch.Tensor): 模型输出值，二维矩阵\n",
    "        \"\"\"\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct = (labels == preds).sum()\n",
    "        self._num_correct += correct.item()\n",
    "        self._num_samples += len(labels)\n",
    "\n",
    "    def compute(self):\n",
    "        \"\"\"得到最终的结果，这里我们需要通过 `reduce` 方法，来将所有节点\n",
    "        上的 self._num_correct 和 self._num_samples 这两个变量以\n",
    "        `sum` 的方式聚合，然后再在主节点上做一个除法即可。\n",
    "        \"\"\"\n",
    "        if dist.is_initialized():\n",
    "            # 仅在分布式环境下做 reduce 操作\n",
    "            dist.reduce(\n",
    "                self._num_correct,\n",
    "                dst=0,\n",
    "                op=torch.distributed.ReduceOp.SUM\n",
    "            )\n",
    "            dist.reduce(\n",
    "                self._num_samples,\n",
    "                dst=0,\n",
    "                op=torch.distributed.ReduceOp.SUM\n",
    "            )\n",
    "\n",
    "        return round((self._num_correct / self._num_samples).item(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0af82-3da0-499a-9e57-7e139ff23c36",
   "metadata": {},
   "source": [
    "下面分别在单进程和分布式环境下使用上面实现的这个 `Accuracy`，结果应该是一样的。\n",
    "\n",
    "首先需要 mock 一些数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37113b8-d69c-4f6f-b9f5-b6985ce0d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/mock.py\n",
    "import torch\n",
    "\n",
    "labels = torch.tensor([2, 0, 2, 1, 0, 1])\n",
    "logits = torch.tensor([\n",
    "    [0.0266, 0.1719, 0.3055],\n",
    "    [0.6886, 0.3978, 0.8176],\n",
    "    [0.9230, 0.0197, 0.8395],\n",
    "    [0.1785, 0.2670, 0.6084],\n",
    "    [0.8448, 0.7177, 0.7288],\n",
    "    [0.7748, 0.9542, 0.8573],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9bf63-9f92-4ec3-ae7c-7d1094420f47",
   "metadata": {},
   "source": [
    "在分布式环境下计算得分："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62c2f0-314c-48ef-8f8f-b8e67f7556b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/test.py\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import logging\n",
    "from helper import init_logger, is_master, is_slave\n",
    "from mock import labels, logits\n",
    "from metric import Accuracy\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "init_logger()\n",
    "\n",
    "labels = labels[dist.get_rank()::dist.get_world_size()]\n",
    "logits = logits[dist.get_rank()::dist.get_world_size()]\n",
    "\n",
    "metric = Accuracy()\n",
    "metric.update(labels, logits)\n",
    "\n",
    "result = metric.compute()\n",
    "\n",
    "if is_master():\n",
    "    logging.info(f\"Accuracy is: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e0618-0b81-4754-aae4-bf57f3586d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo > /tmp/pytorch-dist.log; torchrun --nproc_per_node 2 --nnodes 1 /tmp/test.py && cat /tmp/pytorch-dist.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07d3a9-df56-422b-a9b3-78c8a7519335",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db97cd4-01a1-44f3-bb11-b3bebe12dbf6",
   "metadata": {},
   "source": [
    "现在我们用单进程的方式看看结果是否相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76421102-20bd-4a80-9c1b-3ef9a505ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/test.py\n",
    "import torch\n",
    "from mock import labels, logits\n",
    "from metric import Accuracy\n",
    "\n",
    "\n",
    "metric = Accuracy()\n",
    "metric.update(labels, logits)\n",
    "result = metric.compute()\n",
    "\n",
    "print(f\"Accuracy is: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b0f45-9f80-4ccb-ab21-bf7ae0c04ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /tmp/test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b018e58f-bd01-407d-8f11-36ae07f910ed",
   "metadata": {},
   "source": [
    "## 示例二：支持分布式的 COCO mAP\n",
    "\n",
    "这是个相对复杂的例子，由于 COCO 的 mAP 计算方法不是按单个样本计算得分然后聚合结果的，因此没办法用到 `reduce` 操作。在这个场景中，我们使用 `gather` 操作来获取一些「中间结果」，然后最后在主进程中通过「中间结果」计算最后的得分。\n",
    "\n",
    "一个值得注意的点是，我们应该尽可能得将计算放在各个节点上，而不是仅仅 gather 一下原始数据，然后计算全部交给主进程。因此在实现过程中，需要仔细分析「中间结果」到底是什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362a648-5996-4df4-a105-09d8672fefd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6b90c-57d5-4f24-bb23-3e54e70ac0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/metric.py\n",
    "\n",
    "import torch\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from torchvision.ops import box_iou\n",
    "import torch.distributed as dist\n",
    "from time import time\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import pickle\n",
    "\n",
    "\n",
    "class MeanAveragePrecision():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.iou_thresholds = [round(iou.item(), 2) for iou in torch.arange(0.5, 0.99, 0.05)]\n",
    "        self.rec_thresholds = torch.linspace(0, 1, 101)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self._cm: Dict[float, Dict[float, Dict[str, list]]] = {}\n",
    "\n",
    "    def update(self, y, y_pred) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            y(torch.Tensor): 真值框，shape 为 (N, 5)，N 为该样本框的个数，5 的含义为 (x1, x2, y1, y2, class_number)\n",
    "            y_pred(torch.Tensor): 预测框，shape 为 (M, 6)，M 为预测框的个数，6 的含义为 (x1, x2, y1, y2, confidence, class_number)\n",
    "        \"\"\"\n",
    "        iou = box_iou(y_pred[:, :4], y[:, :4])\n",
    "        categories = torch.cat((y[:, 4], y_pred[:, 5])).unique().tolist()\n",
    "        for category in categories:\n",
    "            if category not in self._cm:\n",
    "                self._cm[category] = {iou: {\"tp\": [], \"fp\": [], \"gt\": [], \"score\": []} for iou in self.iou_thresholds}\n",
    "\n",
    "        for iou_thres_item in self.iou_thresholds:\n",
    "            valid_iou = torch.clone(iou)\n",
    "            valid_iou[iou <= iou_thres_item] = 0\n",
    "            for category in categories:\n",
    "                class_index_gt = y[:, 4] == category\n",
    "                class_index_dt = y_pred[:, 5] == category\n",
    "                class_iou = valid_iou[:, class_index_gt][class_index_dt, :]\n",
    "\n",
    "                if class_iou.shape[1] == 0:\n",
    "                    # no ground truth of the category\n",
    "                    n_gt = 0\n",
    "                    tp = torch.tensor([False] * class_iou.shape[0])\n",
    "                    fp = torch.tensor([True] * class_iou.shape[0])\n",
    "                    score = y_pred[class_index_dt, 4]\n",
    "                elif class_iou.shape[0] == 0:\n",
    "                    # no predictions of the category\n",
    "                    n_gt = class_iou.shape[1]\n",
    "                    tp = torch.tensor([]).bool()\n",
    "                    fp = torch.tensor([]).bool()\n",
    "                    score = torch.tensor([])\n",
    "                else:\n",
    "                    class_iou[~(class_iou == class_iou.max(dim=0)[0])] = 0\n",
    "                    class_iou[~(class_iou.T == class_iou.max(dim=1)[0]).T] = 0\n",
    "\n",
    "                    n_gt = class_iou.shape[1]\n",
    "                    tp = (class_iou != 0).any(dim=1)\n",
    "                    fp = (class_iou == 0).all(dim=1)\n",
    "                    score = y_pred[class_index_dt, 4]\n",
    "                \n",
    "                self._cm[category][iou_thres_item][\"tp\"].append(tp)\n",
    "                self._cm[category][iou_thres_item][\"fp\"].append(fp)\n",
    "                self._cm[category][iou_thres_item][\"gt\"].append(n_gt)\n",
    "                self._cm[category][iou_thres_item][\"score\"].append(score)\n",
    "\n",
    "    def compute(self) -> float:\n",
    "        if dist.is_initialized():\n",
    "            # 在分布式环境下，先调用 gather 搜集不同节点的数据\n",
    "            cms = [None for _ in range(dist.get_world_size())]\n",
    "            pickle.dump(self._cm, open(f\"/home/featurize/{dist.get_rank()}.pkl\", \"wb\"))\n",
    "            dist.gather_object(self._cm, cms if dist.get_rank() == 0 else None, dst=0)\n",
    "\n",
    "            if dist.get_rank() != 0:\n",
    "                return None  # 主节点拿到了其他节点的结果，下面的逻辑只需要在主节点中进行\n",
    "\n",
    "            # 把 cms merge 到 self._cm\n",
    "            self.reset()\n",
    "            for category in set(itertools.chain(*[cm.keys() for cm in cms])):\n",
    "                if category not in self._cm:\n",
    "                    self._cm[category] = {iou: {\"tp\": [], \"fp\": [], \"gt\": [], \"score\": []} for iou in self.iou_thresholds}\n",
    "                for iou_thres in self.iou_thresholds:\n",
    "                    for cm in cms:\n",
    "                        if category not in cm:\n",
    "                            continue\n",
    "                        self._cm[category][iou_thres][\"fp\"].extend(cm[category][iou_thres][\"fp\"])\n",
    "                        self._cm[category][iou_thres][\"tp\"].extend(cm[category][iou_thres][\"tp\"])\n",
    "                        self._cm[category][iou_thres][\"gt\"].extend(cm[category][iou_thres][\"gt\"])\n",
    "                        self._cm[category][iou_thres][\"score\"].extend(cm[category][iou_thres][\"score\"])\n",
    "\n",
    "        results = []\n",
    "        for _, cm in self._cm.items():\n",
    "            category_pr = torch.ones(len(self.iou_thresholds), len(self.rec_thresholds)) * -1\n",
    "\n",
    "            for idx, (_, cm_iou) in enumerate(cm.items()):\n",
    "                n_gt = sum(cm_iou[\"gt\"])\n",
    "                if n_gt == 0:\n",
    "                    # no ground truth of the class\n",
    "                    continue\n",
    "                scores = torch.cat(cm_iou[\"score\"], dim=0)\n",
    "                indx = torch.argsort(scores, descending=True)\n",
    "                \n",
    "                tp = torch.cat(cm_iou[\"tp\"], dim=0)[indx].cumsum(dim=0)\n",
    "                fp = torch.cat(cm_iou[\"fp\"], dim=0)[indx].cumsum(dim=0)\n",
    "                rc = tp / n_gt\n",
    "                pr = tp / (fp + tp)\n",
    "\n",
    "                for i in range(len(tp) - 1, 0, -1):\n",
    "                    if pr[i] > pr[i - 1]:\n",
    "                        pr[i - 1] = pr[i]\n",
    "\n",
    "                inds = torch.searchsorted(rc, self.rec_thresholds)\n",
    "                pr_at_recthres = torch.zeros(len(self.rec_thresholds))\n",
    "                try:\n",
    "                    for ri, pi in enumerate(inds):\n",
    "                        pr_at_recthres[ri] = pr[pi]\n",
    "                except:\n",
    "                    pass\n",
    "                category_pr[idx, :] = pr_at_recthres\n",
    "            if torch.all(category_pr == -1):\n",
    "                continue\n",
    "            category_ap = category_pr[category_pr > -1].mean()\n",
    "            results.append(category_ap)\n",
    "        return round(torch.stack(results).mean().item(), 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b918e0a-a492-4eb8-be18-fac1e96d14c0",
   "metadata": {},
   "source": [
    "Mock 两个样本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79f569-5c54-491c-9ebc-482050b83379",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/mock.py\n",
    "import torch\n",
    "\n",
    "gts = [\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [126, 90, 523, 534, 6],\n",
    "            [190, 304, 249, 369, 1],\n",
    "            [435, 338, 451, 362, 1],\n",
    "            [298, 334, 332, 367, 1],\n",
    "            [174, 170, 203, 192, 1],\n",
    "            [297, 160, 322, 180, 1],\n",
    "            [121, 389, 127, 410, 1],\n",
    "            [568, 316, 611, 404, 6],\n",
    "            [91, 388, 104, 422, 1],\n",
    "            [212, 168, 230, 188, 1],\n",
    "            [78, 377, 97, 429, 1],\n",
    "            [101, 397, 114, 429, 1],\n",
    "            [113, 391, 126, 429, 1],\n",
    "            [502, 315, 565, 384, 6],\n",
    "        ]\n",
    "    ),\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [256, 70, 353, 302, 1],\n",
    "            [87, 184, 240, 324, 1],\n",
    "            [87, 71, 153, 140, 1],\n",
    "            [169, 74, 221, 130, 1],\n",
    "            [387, 60, 475, 113, 1],\n",
    "            [215, 76, 262, 129, 1],\n",
    "            [301, 28, 363, 97, 39],\n",
    "            [39, 0, 75, 14, 1],\n",
    "            [138, 115, 191, 133, 15],\n",
    "            [340, 97, 418, 118, 15],\n",
    "            [213, 230, 241, 263, 40],\n",
    "            [147, 103, 152, 118, 44],\n",
    "            [17, 96, 67, 148, 1],\n",
    "            [49, 80, 102, 142, 1],\n",
    "            [86, 107, 90, 123, 44],\n",
    "            [16, 141, 126, 323, 1],\n",
    "        ]\n",
    "    ),\n",
    "]\n",
    "\n",
    "preds = [\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [124, 90, 522, 534, 1, 6],\n",
    "            [507, 316, 567, 385, 1, 6],\n",
    "            [76, 375, 97, 427, 0.99, 1],\n",
    "            [189, 307, 250, 368, 0.98, 1],\n",
    "            [113, 383, 128, 430, 0.98, 1],\n",
    "            [208, 21, 226, 43, 0.92, 18],\n",
    "            [208, 21, 226, 43, 0.92, 18],\n",
    "            [208, 21, 226, 43, 0.92, 16],\n",
    "            [208, 21, 226, 43, 0.92, 16],\n",
    "            [208, 21, 226, 43, 0.92, 16],\n",
    "            [208, 21, 226, 43, 0.92, 16],\n",
    "            [208, 21, 226, 43, 0.92, 16],\n",
    "            [208, 21, 226, 44, 0.92, 16],\n",
    "            [208, 21, 226, 43, 0.92, 16],\n",
    "            [208, 21, 226, 43, 0.92, 16],\n",
    "            [99, 397, 115, 429, 0.91, 1],\n",
    "            [176, 166, 201, 192, 0.88, 1],\n",
    "            [570, 320, 612, 404, 0.86, 6],\n",
    "            [91, 390, 103, 430, 0.84, 1],\n",
    "            [397, 178, 411, 198, 0.79, 1],\n",
    "            [569, 339, 610, 403, 0.65, 3],\n",
    "            [61, 354, 94, 368, 0.56, 3],\n",
    "            [177, 177, 198, 192, 0.38, 77],\n",
    "        ]\n",
    "    ),\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [262, 71, 350, 297, 1, 1],\n",
    "            [94, 185, 233, 320, 1, 1],\n",
    "            [17, 139, 126, 324, 1, 1],\n",
    "            [214, 231, 241, 263, 1, 40],\n",
    "            [397, 60, 452, 114, 0.99, 1],\n",
    "            [167, 74, 221, 133, 0.99, 1],\n",
    "            [89, 72, 149, 140, 0.99, 1],\n",
    "            [300, 28, 363, 98, 0.99, 39],\n",
    "            [212, 72, 262, 129, 0.99, 1],\n",
    "            [24, 94, 71, 147, 0.98, 1],\n",
    "            [48, 81, 77, 137, 0.96, 1],\n",
    "            [285, 91, 303, 119, 0.92, 40],\n",
    "            [85, 106, 91, 124, 0.89, 44],\n",
    "            [145, 102, 151, 119, 0.87, 44],\n",
    "            [29, 0, 78, 14, 0.68, 1],\n",
    "            [0, 92, 22, 146, 0.61, 1],\n",
    "            [50, 156, 195, 323, 0.56, 1],\n",
    "            [13, 0, 56, 15, 0.53, 1],\n",
    "            [83, 0, 109, 12, 0.50, 1],\n",
    "            [136, 116, 179, 135, 0.43, 15],\n",
    "            [261, 80, 299, 131, 0.40, 1],\n",
    "            [250, 105, 263, 121, 0.31, 40],\n",
    "            [111, 118, 155, 140, 0.30, 31],\n",
    "            [12, 87, 54, 146, 0.29, 1],\n",
    "        ]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043761ac-3db4-4ba0-b8ef-d93f7774b41f",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07bec6e-dd68-4b7d-b40c-f5edded2e3ff",
   "metadata": {},
   "source": [
    "首先测试单进程的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50838da-3cc2-4a44-b968-fb5da90af371",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/test.py\n",
    "\n",
    "import torch\n",
    "from metric import MeanAveragePrecision\n",
    "from mock import gts, preds\n",
    "\n",
    "metric = MeanAveragePrecision()\n",
    "for gt, pred in zip(gts, preds):\n",
    "    metric.update(gt, pred)\n",
    "print(f\"mAP: {metric.compute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca6ebe3-e80a-4107-a218-0be08d1797a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /tmp/test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f0b9c-e362-4945-9d72-f4ab1692659b",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb4d15-872a-4bb1-a284-e8d31af3ca41",
   "metadata": {},
   "source": [
    "测试分布式的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd2c3ee-6859-4e4c-a6b8-a72d3db8e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/test.py\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import logging\n",
    "from helper import init_logger, is_master, is_slave\n",
    "from mock import gts, preds\n",
    "from metric import MeanAveragePrecision\n",
    "\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "init_logger()\n",
    "\n",
    "# master 算第一个样本，slave 算第二个样本。\n",
    "gt = gts[0] if is_master() else gts[1]\n",
    "pred = preds[0] if is_master() else preds[1]\n",
    "\n",
    "metric = MeanAveragePrecision()\n",
    "metric.update(gt, pred)\n",
    "\n",
    "result = metric.compute()\n",
    "\n",
    "if is_master():\n",
    "    logging.info(f\"mAP: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b816e-e2f1-4b29-8ffa-6ae18428c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo /tmp/pytorch-dist.log && torchrun --nproc_per_node 2 --nnodes 1 /tmp/test.py && cat /tmp/pytorch-dist.log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
